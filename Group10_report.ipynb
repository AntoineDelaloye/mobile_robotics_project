{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Robotics Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group 10:  \n",
    "Amine Tourki  \n",
    "Antoine Jérémie Delaloye  \n",
    "Ruben Jungius  \n",
    "Marco Angelo Pontarolo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to navigate a Thymio robot through an environment with obstacles in order to reach a goal position. This project includes four major modules: Global and Local Navigation, Vision and Filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The setup for our project is very simple. It consists of an open arena (no marked boundaries), with black obstacles made of paper, a colored ground (red or green) and a simple flat cirle as an objective. Discussion about the choices can be found in the vision module.  \n",
    "(*insert a good setup image here*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision\n",
    "The vision module in this project is responsible for detecting the obstacles and the goal, the state of the Thymio (position and orientation) as well as constructing a map for the Global Planning module. Most of the vision module is done using the OpenCV library. Below are the choices made for the Arena:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Choice**          | **Reason**                                                                                                                          |\n",
    "|---------------------|-------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Open arena          | The arena was kept open in order to avoid any unnecesary errors due to the hough transform or any other lign detection algorithm    |\n",
    "| Black obstacles     | The obstacles were chosen to be black for the ease of detection using thresholding                                                  |\n",
    "| Round red objective | A circular form was found to be the easiest to detect. The color was chosen red to create an apparent gradient from the map's floor |\n",
    "| Green floor         | The color of the floor was chosen in order to have a great contrast from the obstacles, making their detection much easier          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General vision class\n",
    "The vision module was made into a class to make the extraction of information much easier and add structure to the whole module. An instance of the class is created and can be used to access information about the vision at any time. The main functions provided by the Vision are as follow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Function**           | **Role**                                                                  |\n",
    "|------------------------|---------------------------------------------------------------------------|\n",
    "| vision.openWindow()    | Opens an independent window with the vision of the camera                 |\n",
    "| vision.getRobotPos()   | Returns the current position of the robot in the map (in term of cells)   |\n",
    "| vision.getRobotAngle() | Returns the orientation of the robot (clockwise from the horizontal axis) |\n",
    "| vision.getMap()        | Returns a binary map of the arena (1 for obstacles, 0 is free)            |\n",
    "| vision.getGoal()       | Return the position of the goal in the map                                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thymio detection\n",
    "The detection of the thymio is done using thresholding. A mask is generated from the threshoding which is then further processed to remove any noise. The contour of the thymio can then be and used to extract both the position of the center using the moment of the contour and the orientation by fitting a rectangle on the Thymio and getting the orientation of the fitted rectangle. Follow are the main functions from CV2 used for each part:\n",
    "- Thresholding: `cv2.threshold`\n",
    "- Mask processing: `cv2.morphologyEx`\n",
    "- Finding the contour : `cv2.findContours`\n",
    "- Calculating the moment of the contour: `cv2.moments`\n",
    "- Fitting a rectangle: `cv2.minAreaRect`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of the Thymio detection steps:\n",
    "<center><img src=\"Images/vision_thymio_in_arena.png\"></center>\n",
    "<center>Original image from the camera</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./Images/vision_thymio_threshold_noisy.png\"></center>\n",
    "<center>Thresholding the image to botain the Thymio</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\".\\Images\\vision_thymio_threshold_processed.png\" ...></center>\n",
    "<center>Denoising the mask</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\".\\Images\\vision_thymio_contour.png\" ...></center>\n",
    "<center>Extracting the contour of the Thymio from the mask</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\".\\Images\\vision_thymio_contour_center.png\" ...></center>\n",
    "<center>Calculate the center and orientation of the Thymio using the contour</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function responsible for updating the robot position and orientation is implemented as follows: \n",
    "```python\n",
    "def updateRobot(self):\n",
    "    if self.current_img is None: return\n",
    "    gray = cv2.cvtColor(self.current_img, cv2.COLOR_BGR2GRAY)\n",
    "    thymio_mask = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    opening = cv2.morphologyEx(thymio_mask, cv2.MORPH_OPEN, np.ones((5,5), np.uint8), iterations=7) \n",
    "    contours= cv2.findContours(opening,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    M = cv2.moments(contours[0]) \n",
    "    cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "    h, w = gray.shape[:2]\n",
    "    self.img_ratio = w/h\n",
    "    hb, wb = (int(self.map_size/self.img_ratio),self.map_size)\n",
    "    self.robot_pos = (int(cx/h*hb),int(cy/w*wb))\n",
    "    self.robot_angle = self.rectifyAngle(cv2.minAreaRect(contours[0]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obstacle detection and map generation\n",
    "The same method as for the detection of the Thymio is applied to detect the obstacles but with an inversed binary thresholding instead. The image is also post processed for denoising and filling the possible gaps in the obstacles. The mask is then turned into a binary map and rescaled to the desired size. The same function as before were used plus the following function to resize the binary map:\n",
    "- Resizing the map: `skimage.transform.resize`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an exemple of the obstacles detection and map creation\n",
    "<center><img src=\".\\Images\\vision_obstacle_original.png\" ...></center>\n",
    "<center>Original image from the camera</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\".\\Images\\vision_obstacle_mask_noisy.png\" ...></center>\n",
    "<center>Threshold to obtain the obstacles</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\".\\Images\\vision_obstacle_mask_fill.png\" ...></center>\n",
    "<center>Process to fill the gaps</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\".\\Images\\vision_obstacle_mask_denoise.png\" ...></center>\n",
    "<center>Denoise the mask</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\".\\Images\\vision_obstacle_mask_binary.png\" ...></center>\n",
    "<center>Turn into a binary map</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\".\\Images\\vision_obstacle_mask_rescale.png\" ...></center>\n",
    "<center>Resize to de desired map size</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function used to detect the obstacles and create the map for the global navigation is implemented as follows: \n",
    "```python\n",
    "def createMap(self):\n",
    "    if self.current_img is None: return\n",
    "    gray = cv2.cvtColor(self.current_img,cv2.COLOR_BGR2GRAY)\n",
    "    obst_mask = cv2.threshold(gray, 20, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "    closing = cv2.morphologyEx(obst_mask, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8), iterations=15) \n",
    "    opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN,  np.ones((5,5), np.uint8), iterations=7) \n",
    "    h, w = gray.shape[:2]\n",
    "    self.img_ratio = w/h\n",
    "    binary_map = img_as_bool(resize(opening/opening.max(),(int(self.map_size/self.img_ratio),self.map_size)))\n",
    "    self.map = binary_map.astype(int)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "we'll discuss the conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*insert code here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./Images/vision_thymio_in_arena.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../Images/vision_thymio_in_arena.png\"></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('mobile')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b62b9b2d2eb6a420240c37b2ad343902381595c0efa78d21bbefc4e5a47b7802"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
