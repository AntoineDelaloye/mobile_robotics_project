{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Robotics Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group 10:  \n",
    "Amine Tourki  \n",
    "Antoine Jérémie Delaloye  \n",
    "Ruben Jungius  \n",
    "Marco Angelo Pontarolo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to navigate a Thymio robot through an environment with obstacles in order to reach a goal position. This project includes four major modules: Global and Local Navigation, Vision and Filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The setup for our project is very simple. It consists of an open arena (no marked boundaries), with black obstacles made of paper, a colored ground (red or green) and a simple flat cirle as an objective. Discussion about the choices can be found in the vision module.  \n",
    "(*insert a good setup image here*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision\n",
    "The vision module in this project is responsible for detecting the obstacles and the goal, the state of the Thymio (position and orientation) as well as constructing a map for the Global Planning module. Most of the vision module is done using the OpenCV library. Below are the choices made for the Arena:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Choice**          | **Reason**                                                                                                                          |\n",
    "|---------------------|-------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Open arena          | The arena was kept open in order to avoid any unnecesary errors due to the hough transform or any other lign detection algorithm    |\n",
    "| Black obstacles     | The obstacles were chosen to be black for the ease of detection using thresholding                                                  |\n",
    "| Round red objective | A circular form was found to be the easiest to detect. The color was chosen red to create an apparent gradient from the map's floor |\n",
    "| Green floor         | The color of the floor was chosen in order to have a great contrast from the obstacles, making their detection much easier          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General vision class\n",
    "The vision module was made into a class to make the extraction of information much easier and add structure to the whole module. An instance of the class is created and can be used to access information about the vision at any time. The main functions provided by the Vision are as follow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Function**           | **Role**                                                                  |\n",
    "|------------------------|---------------------------------------------------------------------------|\n",
    "| vision.openWindow()    | Opens an independent window with the vision of the camera                 |\n",
    "| vision.getRobotPos()   | Returns the current position of the robot in the map (in term of cells)   |\n",
    "| vision.getRobotAngle() | Returns the orientation of the robot (clockwise from the horizontal axis) |\n",
    "| vision.getMap()        | Returns a binary map of the arena (1 for obstacles, 0 is free)            |\n",
    "| vision.getGoal()       | Return the position of the goal in the map                                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thymio detection\n",
    "The detection of the thymio is done using thresholding. A mask is generated from the threshoding which is then further processed to remove any noise. The contour of the thymio can then be and used to extract both the position of the center using the moment of the contour and the orientation by fitting a rectangle on the Thymio and getting the orientation of the fitted rectangle. Follow are the main functions from CV2 used for each part:\n",
    "- Thresholding: `cv2.threshold`\n",
    "- Mask processing: `cv2.morphologyEx`\n",
    "- Finding the contour : `cv2.findContours`\n",
    "- Calculating the moment of the contour: `cv2.moments`\n",
    "- Fitting a rectangle: `cv2.minAreaRect`\n",
    "\n",
    "Here is an example of the Thymio detection steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/vision_thymio_in_arena.PNG\"></center>\n",
    "<center>Original image from the camera</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/vision_thymio_threshold_noisy.png\"></center>\n",
    "<center>Thresholding the image to botain the Thymio</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images\\vision_thymio_threshold_processed.png\"></center>\n",
    "<center>Denoising the mask</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images\\vision_thymio_contour.png\"></center>\n",
    "<center>Extracting the contour of the Thymio from the mask</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images\\vision_thymio_contour_center.png\"></center>\n",
    "<center>Calculate the center and orientation of the Thymio using the contour</center>\n",
    "\n",
    "[//]: <> (<center><img src=images/vision_thymio_in_arena.png></center>)\n",
    "[//]: <> (<center>Original image from the camera</center>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function responsible for updating the robot position and orientation is implemented as follows: \n",
    "```python\n",
    "def updateRobot(self):\n",
    "    if self.current_img is None: return\n",
    "    gray = cv2.cvtColor(self.current_img, cv2.COLOR_BGR2GRAY)\n",
    "    thymio_mask = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    opening = cv2.morphologyEx(thymio_mask, cv2.MORPH_OPEN, np.ones((5,5), np.uint8), iterations=7) \n",
    "    contours= cv2.findContours(opening,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    M = cv2.moments(contours[0]) \n",
    "    cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "    h, w = gray.shape[:2]\n",
    "    self.img_ratio = w/h\n",
    "    hb, wb = (int(self.map_size/self.img_ratio),self.map_size)\n",
    "    self.robot_pos = (int(cx/h*hb),int(cy/w*wb))\n",
    "    self.robot_angle = self.rectifyAngle(cv2.minAreaRect(contours[0]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obstacle detection and map generation\n",
    "The same method as for the detection of the Thymio is applied to detect the obstacles but with an inversed binary thresholding instead. The image is also post processed for denoising and filling the possible gaps in the obstacles. The mask is then turned into a binary map and rescaled to the desired size. The same function as before were used plus the following function to resize the binary map:\n",
    "- Resizing the map: `skimage.transform.resize`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an exemple of the obstacles detection and map creation\n",
    "<center><img src=\"images\\vision_obstacle_original.png\"></center>\n",
    "<center>Original image from the camera</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images\\vision_obstacle_mask_noisy.png\"></center>\n",
    "<center>Threshold to obtain the obstacles</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images\\vision_obstacle_mask_fill.png\"></center>\n",
    "<center>Process to fill the gaps</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images\\vision_obstacle_mask_denoise.png\"></center>\n",
    "<center>Denoise the mask</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images\\vision_obstacle_mask_binary.png\"></center>\n",
    "<center>Turn into a binary map</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images\\vision_obstacle_mask_rescale.png\"></center>\n",
    "<center>Resize to de desired map size</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function used to detect the obstacles and create the map for the global navigation is implemented as follows: \n",
    "```python\n",
    "def createMap(self):\n",
    "    if self.current_img is None: return\n",
    "    gray = cv2.cvtColor(self.current_img,cv2.COLOR_BGR2GRAY)\n",
    "    obst_mask = cv2.threshold(gray, 20, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "    closing = cv2.morphologyEx(obst_mask, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8), iterations=15) \n",
    "    opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN,  np.ones((5,5), np.uint8), iterations=7) \n",
    "    h, w = gray.shape[:2]\n",
    "    self.img_ratio = w/h\n",
    "    binary_map = img_as_bool(resize(opening/opening.max(),(int(self.map_size/self.img_ratio),self.map_size)))\n",
    "    self.map = binary_map.astype(int)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Local Navigation module is responsible for:\n",
    "- Finding the right speed value of the motors to reach the goal\n",
    "- Chose whether to follow the path created from the A* algorithm or to avoid a local obstacle\n",
    "\n",
    "A local obstacle is a 3D obstacle which wasn't present on the map at the moment of calculating the planning for the optimal path. We chose to have it white for a better detection from the sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Useful constants**                            | **Purpose**                                                                |\n",
    "|---------------------------|-------------------------------------------------------------------------------------------------|\n",
    "| obstThrL = 500    | This constant is used to know if there are no local objects in front of the Thymio. The value should be 0, but we have a higher value to avoid disturbances.    |\n",
    "| obstThrH = 900    | This constant is used to detect an obstacle near the proximity sensors. The range is [1000, 4500] when he is detecting something and a high value means that the obstacle is nearer to the Thymio. The range is [1, 14] cm   |\n",
    "| obstSpeedGain = [0.1, 0.06, 0, -0.06, -0.1]     | This is a vector containing the necessary gains for motor speed to avoid obstacles while navigating with local navigation. They are related to the first 5 proximity sensors from front left to front right.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Local Navigation functions\n",
    "The Local Navigation module was made without a class. The main functions provided by the Local Navigation are as follow:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Function**           | **Role**                                                                  |\n",
    "|------------------------|---------------------------------------------------------------------------|\n",
    "| obstacleAvoidance()    | It has as parameters the position of the Thymio (position_x, position_y) and returns saved_pos_idx which corrisponds to the index of the coordinates from path matrix. This position is the one of the Thymio when he first detect a local obstacle         |\n",
    "| checkState()           | Returns the current position of the robot in the map (in term of cells)   |\n",
    "| currentPositionIndex() | Returns the index from path matrix of the current position                |\n",
    "| motionControl()        | Returns motors left and right speed                                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local obstacle detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm to detect the local obstacle works in this way: \n",
    "- Proximity sensors refresh their values continuously while following the path generated from A star algorithm. \n",
    "- Once a local obstacle is detected, the proximity sensor value pass a threshold value of 900, which switch the mode from A star algorithm to obstacle avoidance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local obstacle circumnavigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to pass an obstacle the Thymio save his position when the obstacle is detected. After this he verifies if the obstacle is on his right or his left by compare values of proximity sensors: a greater value means a closer obstacle and the Thymio will first turn on the opposite direction. For instance if the value on the right are bigger than the one on the left, then he will take a clockwise direction by increasing the speed of the right motor and decrease the speed of the left motor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images\\obstacle_detection.png\" width = 400></center>\n",
    "<center> The moment of obstacle detection at a distance of approximately 14 cm </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation is done until the sensors are free again as shown in the image below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images\\obstacle_avoided.png\" width = 400></center>\n",
    "<center> No more obstacle detected </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this moment the robot will continue turning, at a fixed speed of 200 for the external motor and 100 for the internal motor, and looking for one of the coordinates from the original path planning. If his positon is again on one of the coordinates from path planning, then he switch his mode from obstacle avoidance to A star algorithm.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm is responsible for finding the original path.\n",
    "Here is very important to have the saved position and his corresponding index, when the local obstacle is detected (saved_pos and saved_pos_idx). \n",
    "The resoning is that from the saved index we check all the cosecutive coordinates until the final objective, except from ###, to compare the current position of the Thymio and the position of all the possibile targets. If they match it means that the Thymio circumnavigated the obstacle and he can continue on the original path. \n",
    "```python\n",
    "def funtion()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "we'll discuss the conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*insert code here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b62b9b2d2eb6a420240c37b2ad343902381595c0efa78d21bbefc4e5a47b7802"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
